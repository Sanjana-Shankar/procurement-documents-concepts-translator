# Procurement Spend Normalizer

## ğŸ“Œ Overview
The **Procurement Spend Normalizer** is a finance-focused application that helps enterprises unify and analyze their procurement spend data.  
Enterprises often receive **purchase orders and invoices** in mixed formats with inconsistent naming conventions (e.g., "Freight" vs. "Logistics" vs. "Shipping").  
This app extracts data from scanned invoices, normalizes cost categories, and provides a clean **unified spend table** for finance teams to run analytics.  

Additionally, the app includes a **Q&A chatbot** powered by Pathwayâ€™s Retrieval-Augmented Generation (RAG) framework, allowing users to clarify finance terms and navigate spend data interactively.

## Problem Statement

Finance teams at growing startups and enterprises often face a common challenge: managing messy, unstructured procurement data. Invoices, receipts, and purchase orders arrive in multiple formats with inconsistent terminologyâ€”think â€œFreight,â€ â€œLogistics,â€ and â€œShippingâ€ all referring to the same category. Manually cleaning, categorizing, and analyzing this data is time-consuming, error-prone, and inefficient.

The Procurement Spend Normalizer solves this problem by automatically extracting, cleaning, and normalizing procurement data, mapping inconsistent terms into unified spend categories. Beyond simple data cleaning, it provides a smart, interactive chatbot that allows finance teams to ask natural language questions like:

â€œWhich invoices had professional services over $3,000?â€

â€œHow much did we spend on Transportation last quarter?â€

The system flags anomalies and high-value spend, links every answer back to the original line items for auditing, and exports data as clean Excel sheets or dashboards.

With the Procurement Spend Normalizer, finance teams can turn chaotic piles of documents into actionable intelligence in secondsâ€”reducing manual work, improving spend visibility, and enabling faster, data-driven decisions
---

## ğŸš€ Features
- **Document Extraction**: Uses [LandingAI](https://landing.ai/) to parse purchase orders and invoices from PDFs/scans.  
- **Spend Normalization**: Maps inconsistent labels into unified categories (e.g., "Freight/Logistics/Shipping" â†’ "Transportation").  
- **Q&A Chatbot**: Built with [Pathway RAG](https://pathway.com/), allowing users to ask questions about finance terminology and the normalized dataset.  
- **Database Integration**: Store structured spend data in either **MongoDB** or **PostgreSQL**.  
- **Frontend Dashboard**: A React UI to upload invoices, visualize normalized data, and chat with the Q&A assistant.  

---

## ğŸ›  Tech Stack
- **Frontend**: React (TypeScript, Vite/CRA, TailwindCSS)  
- **Backend**: FastAPI (Python)  
- **Database**:  
  - Option A: MongoDB (via `pymongo`)  
  - Option B: PostgreSQL (via `SQLAlchemy` + `asyncpg` or `psycopg2-binary`)  
- **AI/ML Services**:  
  - [LandingAI](https://landing.ai/) â†’ OCR + Document parsing  
  - [Pathway RAG](https://pathway.com/) â†’ Finance Q&A chatbot  

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repo
```
git clone https://github.com/your-org/procurement-spend-normalizer.git
cd procurement-spend-normalizer
```
### 2ï¸âƒ£ Backend Setup (FastAPI)
#### Create virtual environment
##### macOS/Linux 
```
python3 -m venv venv
source venv/bin/activate   
```
##### Windows
```
python3 -m venv venv
venv\Scripts\activate      
```
#### Install dependencies
```bash
pip install --upgrade pip setuptools wheel
pip install fastapi uvicorn sqlalchemy pymongo asyncpg
```
```
# If you prefer PostgreSQL with psycopg2 instead of asyncpg:
pip install psycopg2-binary
```

#### Run backend
```bash
# Backend runs at: http://127.0.0.1:8000
uvicorn backend.main:app --reload
```

### 3ï¸âƒ£ Frontend Setup (React)
```bash
# Frontend runs at: http://localhost:5173 (or CRA default http://localhost:3000).
cd frontend
npm install
npm run dev
```

### ğŸ“‚ Project Structure
```
graphql

procurement-spend-normalizer/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ main.py        # FastAPI entry point
â”‚   â”œâ”€â”€ models/        # SQLAlchemy models
â”‚   â”œâ”€â”€ routes/        # API routes
â”‚   â”œâ”€â”€ services/      # LandingAI + Pathway integration
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ services/  # API calls to backend
â”‚â”€â”€ README.md
```
